---
title: "Miswanting"
authors: - "Allison Smith"
         - "Janis Lesinskis"
date: "2019-08-06"
contentType: "blog"
callToActionText:

---

Anyone in marketing will tell you that people make decisions based on emotion, not logic. We can see this in action when researching a new product or service, whether it's a project management system you'll use with your team, a new laptop for work or the dishwasher you've been putting off replacing. 

We humans like to believe that we know what we want, and will continue to want those things in the future. But sometimes, that isn't the case and we make an inaccurate prediction about how and what we'll feel when we finally get that thing - we *miswant* something. So, what exactly is miswanting? How do we avoid it, and the subsequent impacts of a poor prediction or bad decision? We'll cover that in this post (at least in one context).

Psychologists Dan Gilbert and Tim Wilson, who study *affective forecasting*, define *miswanting* as follows:


> Miswanting refers to the fact that people sometimes make mistakes about how much they will like something in the future. That is, people often mispredict the duration of their good and bad feelings. 
> 

When we're charged with making what may easily be million-dollar decisions about the direction of a project, features we need in our software, hiring a new team member or the recruiting process itself, we can't afford miscalculations. One critical mistake could mean we chart the wrong path and end up with a solution that doesn't satisfy our pain points or solve our problem. 

For example, imagine the following situation: Paul is an IT manager for a manufacturing company with 150 employees. He needs to find a better system for employee onboarding, as the company's current process is piecemeal and convoluted. He's even a bit embarrassed by it, so he commits to tackling the issue.

First, he consults his HR department (and any others involved in the onboarding process) to define their needs, then starts shopping for an agency to build a custom, web-based app where every new employee's information, the documents they exchange with them, and training materials will be centralized. 

He started this process with a list of basic requirements he knew he definitely needed, but then he read a well-written article in an industry magazine detailing the benefits of a few features that weren't included in his inventory. These new features sound so much better than what he and his staff had agreed to originally. Besides, what good is a system they may have to upgrade and retrain on in a year or two? 

Paul fears that by not giving his staff the best possible system, he'd be shortchanging them. He's convinced they need these features, so he tables it with both the agency and his staff. While the agency agrees with him and jumps at the chance to further customize (and make more profit from the project), the employees discourage adding to the feature list. They contend they'll already have to learn a new system. Why add extra complexity where it's currently not warranted (and potentially will never be used)? After a couple of weeks of arguing, they relent and Paul signs off on the deal. Six months after implementation, Paul is dealing with some livid staff, one confused new employee, and is bewildered at how he was conned into wanting something he thought he liked the looks of, even needed. 

In the conclusion of a paper summarizing their study, Gilbert and Wilson explain how our wants can steer us wrong, even when we're sure of them:

> First, our wants are, like any other prediction, susceptible to error. We may misconstrue events, misunderstand ourselves, misinterpret our feelings - and any of these mistakes can be a cause of miswanting. In short, things do not always feel the way we expect them to feel. Second, even if we could predict how much we would like an event when it happened, we might still be unable to predict how that event would affect us in the long run.

In this case, we can take a few lessons from the example above:

- Having no system is very different to having a system, and again very different than having a complex system.   
- Paul let his embarrassment about and memories of the non-existent system his team had in the past cloud his judgement about requirements. 
- He overlooked the downside of moving from no system to a complex system, and assumed  a complex system with more features meant it would be a better system. In reality, the complexity negatively impacted his staff. 

Sometimes, when complex systems are implemented, those using it find that not only does it not live up to expectations, but they may actively *dislike* the system they receive. 



## How to avoid miswanting when making decisions